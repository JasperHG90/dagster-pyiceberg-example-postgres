{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access the Iceberg catalog\n",
    "\n",
    "This notebook shows you how to load iceberg tables using [pyiceberg](https://github.com/apache/iceberg-python).\n",
    "\n",
    "Note: before running this notebook, be sure to materialize the dagster assets. Otherwise, the tables will not be available.\n",
    "\n",
    "## Connecting to the catalog\n",
    "\n",
    "You can connect to the postgresql catalog using the `pyiceberg.catalog.sql.SqlCatalog` object. The required credentials for MinIO (storage) and postgresql are available as environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyiceberg.catalog.sql import SqlCatalog\n",
    "\n",
    "\n",
    "catalog = SqlCatalog(\n",
    "    name=\"dagster_example_catalog\",\n",
    "    **{\n",
    "        \"uri\": os.environ[\"DAGSTER_SECRET_PYICEBERG_CATALOG_URI\"],\n",
    "        \"s3.endpoint\": os.environ[\"DAGSTER_SECRET_S3_ENDPOINT\"],\n",
    "        \"s3.access-key-id\": os.environ[\"DAGSTER_SECRET_S3_ACCESS_KEY_ID\"],\n",
    "        \"s3.secret-access-key\": os.environ[\n",
    "            \"DAGSTER_SECRET_S3_SECRET_ACCESS_KEY\"\n",
    "        ],\n",
    "        \"py-io-impl\": \"pyiceberg.io.fsspec.FsspecFileIO\",\n",
    "        \"warehouse\": os.environ[\"DAGSTER_SECRET_S3_WAREHOUSE\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't see a namespace here, be sure to run `just nc` from the repository root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('air_quality',)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.list_namespaces()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've materialized the `daily_air_quality_data`, then you'll see it listed under the `air_quality` namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('air_quality', 'daily_air_quality_data')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.list_tables(namespace=\"air_quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load the table as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "daily_air_quality_data(\n",
       "  1: station_number: optional string,\n",
       "  2: value: optional double,\n",
       "  3: timestamp_measured: optional string,\n",
       "  4: formula: optional string,\n",
       "  5: measurement_date: optional date,\n",
       "  6: __index_level_0__: optional long\n",
       "),\n",
       "partition by: [measurement_date],\n",
       "sort order: [],\n",
       "snapshot: Operation.APPEND: id=3803352301006519707, schema_id=0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_daily_air_quality_data = catalog.load_table(\"air_quality.daily_air_quality_data\")\n",
    "\n",
    "table_daily_air_quality_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the table is partitioned by the column `measurement_date`. This is because the `daily_air_quality_data` is partitioned on this column:\n",
    "\n",
    "```python\n",
    "# src/dagster_pyiceberg_example/partitions.py\n",
    "daily_partition = DailyPartitionsDefinition(\n",
    "    start_date=datetime.datetime(2024, 10, 20),\n",
    "    end_offset=0,\n",
    "    timezone=\"Europe/Amsterdam\",\n",
    "    fmt=\"%Y-%m-%d\",\n",
    ")\n",
    "\n",
    "# src/dagster_pyiceberg_example/assets/__init__.py\n",
    "@asset(\n",
    "    description=\"Copy air quality data to iceberg table\",\n",
    "    compute_kind=\"iceberg\",\n",
    "    io_manager_key=\"warehouse_io_manager\",\n",
    "    partitions_def=daily_partition,\n",
    "    ins={\n",
    "        \"ingested_data\": AssetIn(\n",
    "            \"air_quality_data\",\n",
    "            # NB: need this to control which downstream asset partitions are materialized\n",
    "            partition_mapping=MultiToSingleDimensionPartitionMapping(\n",
    "                partition_dimension_name=\"daily\"\n",
    "            ),\n",
    "            input_manager_key=\"landing_zone_io_manager\",\n",
    "            # NB: Some partitions can fail because of 500 errors from API\n",
    "            #  So we need to allow missing partitions\n",
    "            metadata={\"allow_missing_partitions\": True},\n",
    "        )\n",
    "    },\n",
    "    code_version=\"v1\",\n",
    "    group_name=\"measurements\",\n",
    "    metadata={\n",
    "        \"partition_expr\": \"measurement_date\",\n",
    "    },\n",
    ")\n",
    "def daily_air_quality_data():\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the table metadata in the snapshot information. This also contains a reference to the dagster run id and partition key that generated the snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'snapshot-id': 3803352301006519707,\n",
       " 'sequence-number': 1,\n",
       " 'timestamp-ms': 1731148151326,\n",
       " 'manifest-list': 's3://warehouse/air_quality.db/daily_air_quality_data/metadata/snap-3803352301006519707-0-a7e56d49-35c0-4bb5-a618-1936788e9144.avro',\n",
       " 'summary': {'operation': 'append',\n",
       "  'added-files-size': '33364',\n",
       "  'added-data-files': '1',\n",
       "  'added-records': '11288',\n",
       "  'changed-partition-count': '1',\n",
       "  'created_by': 'dagster',\n",
       "  'dagster_run_id': 'ff374ece-7030-4d39-9f0f-3d69b85ed81b',\n",
       "  'dagster_partition_key': '2024-11-08',\n",
       "  'total-data-files': '1',\n",
       "  'total-delete-files': '0',\n",
       "  'total-records': '11288',\n",
       "  'total-files-size': '33364',\n",
       "  'total-position-deletes': '0',\n",
       "  'total-equality-deletes': '0'},\n",
       " 'schema-id': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_daily_air_quality_data.snapshots()[0].model_dump()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
